# 액티그래피에서 특징 추출

## Depression Level Classification Using Machine Learning Classifiers Based on Actigraphy Data





 Fourteen circadian rhythm features

1.minimum

2.Amplitude

3.Alpha

4.Beta

5.Acrotime

6.Upmesor

7.Downmesor

8.Mesor

9.f_pseudo

10.interdaily stability (IS)

11.intradaily variability (IV)

12.relative amplitude (RA)

13.M10

14.L5





특징 추출 및 분류에 이틀의 액티그래피 데이터가 최적임을 확인함

이 연구의 결과는 우울증의 식별과 액티그래피 데이터의 적용 측면에서 우울증과 신체 활동의 관계에 대한 새로운 통찰력을 제공함



활동 변화를 분석하기 위해 웨어러블 장치를 사용하여 수집된 액티그래피 시계열 데이터를 사용했습니다

액티그래피에서 활동 패턴을 추론하기 위해 액티그래피 시계열(예: 피크, 기울기, 진폭)의 특성을 코사인 모델링(cosinor modeling)에서 지수 [27]–[30]로 계산했습니다.

이 지수들은 참가자들의 일주기 리듬 주기를 나타내며, 이는 우울증의 주요 증상을 나타냅니다



depression levels

- mild
- moderate
- severe



우리는 동일한 참가자의 인구 통계학적, 신체 활동, 주관적 건강 상태 및 정신 건강 변수뿐만 아니라 액티그래피 데이터(Figure 1)를 수집했습니다.





non-parametric features

1. interdaily stability (IS)

2. intradaily variability (IV)

3. total activity of the ten most active hours (M10)

4. total activity of the five least active hours (L5)



 parametric features

1. minimum

2. alpha

3. beta

4. acrotime

5. amplitude

6. mesor

7. upmesor

8. downmesor

9. f_pseudo



Classification algorithms

1. XGBoost classifier

2. support vector classifier (SVC)

3. logistic regression (LR)

4. multilayer perceptron (MLP)



evaluation metrics

1. accuracy

2. precision

3. recall

4. F1-score

5. receiver operating characteristic (ROC) curve

6. area under the curve (AUC)



 The major contributions of this study

(1) We proposed an ML-based classification framework for depression levels based on the circadian rhythm characteristics embedded in physical activity. In addition, we evaluated the performance of the model under various conditions, including binary and multiclass classification, on a large dataset. Moreover, we compared the classification performance of commonly used ML classification algorithms: XGBoost classifier, SVC, MLP classifier, and LR; 

(2) Advancing from analyzing simple characteristics of physical activity data, we extracted various features about the inherent circadian rhythm of activity from participants. Furthermore, we identified the optimal length of actigraphy data for extraction of circadian rhythm features. In addition, we confirmed that the feature importance of the trained XGBoost model in our framework was in agreement to that of previous studies





## METHODS



Six steps in out experimental design

1. Extract interested category variables and combine with actigraphy
2. Extract circadian indices from actigraphy
3. Check distribution of features and apply log transform, standardization
4. Select features based on regression models
5. Generate siz conditions datasets to evaluate optimal length of actigraphy data
6. Train and test four classification algorithms with six conditions dataset



인구 통계학, 신체 활동, 정신 건강, 주관적 건강 상태 변수를 추출하고 한국 국민건강영양조사(KNHANES) 데이터 세트에서 액티그래피 데이터를 수집



매개 변수 및 비 매개 변수 방법을 사용하여 액티그래피 데이터에서 13개의 순환 지수를 추출



액티그래피 수집 도구: ActiGraph GTX3





### Data Preprocessing



1. COLLECT AND COMBINE ACTIGRAPHY AND INTERESTED VARIABLES FROM DATASET



2. EXTRACTION OF PARAMETRIC AND NON-PARAMETRIC CIRCADIAN INDICES





#### Interdaily stability



본 연구에서는 액티그래피 샘플의 수를 24-h 값으로 정규화하여 수일에 걸친 활동의 안정성을 계산하였습니다



```python
def interdaily_stability(df: pd.DataFrame) -> float:
    X_mean = df["activity"].mean()

    hourly_means = df.resample("H", on="timestamp").mean()["activity"].values
    p = len(hourly_means)

    numerator = (1/p) * np.sum(np.square((hourly_means - X_mean)))
    denominator = df["activity"].var()

    return numerator / denominator
```



```python
def interdaily_stability(df: pd.DataFrame,activity_col) -> float:

'''
Interdaily stability was centered and normalized by 
subtracting the overall mean and dividing by the overall 
standard deviation.

ref: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4542004/
'''

# Calculating Mean of the OP Signal
X_mean = df[activity_col].mean()
# Converting to hourly format and computing mean per hour
hourly_means = df.resample("H", on="timestamp").mean()[activity_col].values
# Capturing number of hours we have in our dataset
p = len(hourly_means)
# Centering and normalizing by subtracting the overall mean
numerator = (1/p) * np.sum(np.square((hourly_means - X_mean)))
# Overall standard deviation
denominator = df[activity_col].var()

return numerator / denominator
```





















https://stackoverflow.com/questions/68794330/how-to-calculate-interdaily-stability-for-signal-in-python













<br/>

<br/>

## Reference

- https://ieeexplore.ieee.org/document/9514893

